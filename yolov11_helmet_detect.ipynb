{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72b3b670",
   "metadata": {},
   "source": [
    "# YOLOv11 Helmet Detection: Training and Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbabe80",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "!pip install uv && uv pip install --upgrade pip && uv pip install -r requirements.txt\n",
    "!uv pip install datasets ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e51d0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "from datasets import load_dataset\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"--- Imports Loaded ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e0ed25",
   "metadata": {},
   "source": [
    "## Section 1: Load Dataset from Hugging Face\n",
    "\n",
    "Load the helmet detection dataset from Hugging Face instead of using a local dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed36fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Section 1: Load Dataset from Hugging Face ---\n",
    "ds = load_dataset(\"keremberke/hard-hat-detection\", name=\"full\")\n",
    "print(f\"Dataset loaded with {len(ds['train'])} training, {len(ds['validation'])} validation, and {len(ds['test'])} test examples\")\n",
    "\n",
    "# Display an example\n",
    "example = ds['train'][0]\n",
    "print(\"Sample example keys:\", example.keys())\n",
    "print(f\"Image dimensions: {example['image'].size}\")\n",
    "print(f\"Annotations: {example['objects']}\")\n",
    "\n",
    "# Display the first image with its annotations\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(example['image'])\n",
    "for i in range(len(example['objects']['id'])):\n",
    "    bbox_coords = example['objects']['bbox'][i]\n",
    "    xmin, ymin, width, height = bbox_coords\n",
    "    xmax, ymax = xmin + width, ymin + height\n",
    "    category_id = example['objects']['category'][i]\n",
    "    # Convert category_id to category name if needed\n",
    "    category = list(class_map.keys())[category_id] if 'class_map' in locals() else f\"Class {category_id}\"\n",
    "    plt.gca().add_patch(plt.Rectangle((xmin, ymin), width, height, \n",
    "                                    fill=False, edgecolor='red', linewidth=2))\n",
    "    plt.text(xmin, ymin, category, bbox=dict(facecolor='red', alpha=0.5))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb9392f",
   "metadata": {},
   "source": [
    "## Section 2: Convert Dataset to YOLO Format\n",
    "\n",
    "The Hugging Face dataset needs to be converted to a format compatible with YOLO training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46d5588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Section 2: Convert Dataset to YOLO Format ---\n",
    "# Create directories for YOLO dataset\n",
    "DATASET_DIR = Path('hf_helmet_dataset')\n",
    "IMAGES_DIR = DATASET_DIR / 'images'\n",
    "LABELS_DIR = DATASET_DIR / 'labels'\n",
    "\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    (IMAGES_DIR / split).mkdir(parents=True, exist_ok=True)\n",
    "    (LABELS_DIR / split).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define class mapping\n",
    "class_map = {\n",
    "    'helmet': 0,\n",
    "    'no-helmet': 1\n",
    "}\n",
    "\n",
    "# Function to convert dataset to YOLO format\n",
    "def convert_to_yolo_format(dataset, split):\n",
    "    for i, example in enumerate(dataset[split]):\n",
    "        # Save image\n",
    "        img = example['image']\n",
    "        img_path = IMAGES_DIR / split / f\"{i}.jpg\"\n",
    "        img.save(img_path)\n",
    "        \n",
    "        # Create YOLO format labels\n",
    "        img_width, img_height = img.size\n",
    "        label_path = LABELS_DIR / split / f\"{i}.txt\"\n",
    "        \n",
    "        with open(label_path, 'w') as f:\n",
    "            for j in range(len(example['objects']['id'])):\n",
    "                # Get bbox coordinates\n",
    "                bbox_coords = example['objects']['bbox'][j]\n",
    "                xmin, ymin, width, height = bbox_coords\n",
    "                xmax, ymax = xmin + width, ymin + height\n",
    "                \n",
    "                # Convert to YOLO format (normalized)\n",
    "                x_center = (xmin + width/2) / img_width\n",
    "                y_center = (ymin + height/2) / img_height\n",
    "                width_norm = width / img_width\n",
    "                height_norm = height / img_height\n",
    "                \n",
    "                # Get class id\n",
    "                category_id = example['objects']['category'][j]\n",
    "                \n",
    "                # Write to file\n",
    "                f.write(f\"{category_id} {x_center} {y_center} {width_norm} {height_norm}\\n\")\n",
    "    \n",
    "    return len(dataset[split])\n",
    "\n",
    "# Convert the datasets\n",
    "print(\"Converting dataset to YOLO format...\")\n",
    "train_count = convert_to_yolo_format(ds, 'train')\n",
    "val_count = convert_to_yolo_format(ds, 'validation')\n",
    "test_count = convert_to_yolo_format(ds, 'test')\n",
    "print(f\"Converted {train_count} training, {val_count} validation, and {test_count} test examples\")\n",
    "\n",
    "# Create YAML configuration for YOLO\n",
    "yaml_content = {\n",
    "    'path': str(DATASET_DIR.absolute()),\n",
    "    'train': 'images/train',  # Use relative paths instead of absolute\n",
    "    'val': 'images/validation',  # Use relative paths instead of absolute\n",
    "    'test': 'images/test',  # Use relative paths instead of absolute\n",
    "    'nc': len(class_map),\n",
    "    'names': list(class_map.keys())\n",
    "}\n",
    "\n",
    "# Save YAML file\n",
    "yaml_path = DATASET_DIR / 'data.yaml'\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(yaml_content, f)\n",
    "\n",
    "print(f\"Created YOLO configuration at {yaml_path}\")\n",
    "print(yaml_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78956e0f",
   "metadata": {},
   "source": [
    "## Section 3: Define Configuration and Model\n",
    "\n",
    "Define paths, model variant, and load the base model and dataset configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4c8855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Section 3: Define Configuration and Model ---\n",
    "DATA_YAML_PATH = str(yaml_path)  # Use the newly created YAML file\n",
    "MODEL_VARIANT = 'yolo11n.pt'  # Using YOLOv11 nano variant\n",
    "\n",
    "# Load the base model\n",
    "model = YOLO(MODEL_VARIANT)\n",
    "print(f\"Base model '{MODEL_VARIANT}' loaded.\")\n",
    "\n",
    "# Verify dataset configuration\n",
    "try:\n",
    "    with open(DATA_YAML_PATH, 'r') as f:\n",
    "        data_config = yaml.safe_load(f)\n",
    "        print(\"Dataset configuration loaded successfully:\")\n",
    "        print(data_config)\n",
    "        # Basic validation (check if paths exist)\n",
    "        required_paths = [\n",
    "            data_config.get('train'),\n",
    "            data_config.get('val'),\n",
    "            data_config.get('test')\n",
    "        ]\n",
    "        for p in required_paths:\n",
    "            if p and not os.path.exists(p):\n",
    "                print(\n",
    "                    f\"Warning: Path '{p}' specified in {DATA_YAML_PATH} \"\n",
    "                    f\"might not exist relative to the current directory.\"\n",
    "                )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading or validating {DATA_YAML_PATH}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ae3ef9",
   "metadata": {},
   "source": [
    "## Section 4: Train the Model\n",
    "\n",
    "Define training parameters and start the training process using the loaded configuration and base model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538d04b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Section 4: Train the Model ---\n",
    "# Training parameters\n",
    "EPOCHS = 50\n",
    "IMG_SIZE = 640\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "print(f\"Starting training for {EPOCHS} epochs...\")\n",
    "\n",
    "# Initialize variables for results\n",
    "results_dir = None\n",
    "TRAINING_SUCCESS = False\n",
    "\n",
    "# Start training\n",
    "try:\n",
    "    results = model.train(\n",
    "        data=DATA_YAML_PATH,\n",
    "        epochs=EPOCHS,\n",
    "        imgsz=IMG_SIZE,\n",
    "        batch=BATCH_SIZE,\n",
    "        # device='mps',          # Specify Apple Silicon GPU\n",
    "        device='cuda',          # Specify Nvidia GPU\n",
    "        cache=True,             # Cache dataset images in RAM\n",
    "        amp=True,              # Ensure Automatic Mixed Precision is enabled\n",
    "        workers=8,             # Number of worker threads\n",
    "        project='runs/detect',  # Project directory for results\n",
    "        name='helmet_train'     # Experiment name\n",
    "    )\n",
    "\n",
    "    print(\"Training finished.\")\n",
    "    # Store the results directory for later use\n",
    "    results_dir = results.save_dir\n",
    "    print(f\"Results saved to: {results_dir}\")\n",
    "    TRAINING_SUCCESS = True\n",
    "\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"An error occurred during training: {e}\", traceback.format_exc())\n",
    "    TRAINING_SUCCESS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341a962a",
   "metadata": {},
   "source": [
    "## Display Training Results\n",
    "\n",
    "If training completed successfully, display the generated plots and validation images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8b6245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display paths to important results files (plots)\n",
    "if TRAINING_SUCCESS and results_dir:\n",
    "    print(\"Displaying training results plots:\")\n",
    "\n",
    "    confusion_matrix_path = os.path.join(results_dir, 'confusion_matrix.png')\n",
    "    results_plot_path = os.path.join(results_dir, 'results.png')\n",
    "    val_labels_path = os.path.join(results_dir, 'val_batch0_labels.jpg')\n",
    "    val_pred_path = os.path.join(results_dir, 'val_batch0_pred.jpg')\n",
    "\n",
    "    if os.path.exists(confusion_matrix_path):\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        display(Image(filename=confusion_matrix_path))\n",
    "    else:\n",
    "        print(f\"Confusion matrix not found at: {confusion_matrix_path}\")\n",
    "\n",
    "    if os.path.exists(results_plot_path):\n",
    "        print(\"\\nResults Plot:\")\n",
    "        display(Image(filename=results_plot_path))\n",
    "    else:\n",
    "        print(f\"Results plot not found at: {results_plot_path}\")\n",
    "\n",
    "    if os.path.exists(val_labels_path):\n",
    "        print(\"\\nValidation Batch 0 Labels:\")\n",
    "        display(Image(filename=val_labels_path))\n",
    "    else:\n",
    "        print(f\"Validation labels image not found at: {val_labels_path}\")\n",
    "\n",
    "    if os.path.exists(val_pred_path):\n",
    "        print(\"\\nValidation Batch 0 Predictions:\")\n",
    "        display(Image(filename=val_pred_path))\n",
    "    else:\n",
    "        print(f\"Validation predictions image not found at: {val_pred_path}\")\n",
    "elif not TRAINING_SUCCESS:\n",
    "    print(\"Training did not complete successfully. Cannot display results plots.\")\n",
    "else:\n",
    "    print(\"Results directory not found. Cannot display results plots.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9317bd7",
   "metadata": {},
   "source": [
    "## Section 7: Load Trained Model and Run Inference\n",
    "\n",
    "Load the best weights from the completed training run and prepare for inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c7db69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Section 7: Load Trained Model ---\n",
    "\n",
    "model_trained = None # Initialize variable\n",
    "\n",
    "# Only proceed if training seemed to complete and results were saved\n",
    "if TRAINING_SUCCESS and results_dir:\n",
    "    # Path to the trained model weights\n",
    "    TRAINED_MODEL_PATH = os.path.join(results_dir, 'weights/best.pt')\n",
    "\n",
    "    # Check if the trained model file exists\n",
    "    if not os.path.exists(TRAINED_MODEL_PATH):\n",
    "        print(f\"Error: Trained model not found at {TRAINED_MODEL_PATH}\")\n",
    "        print(\"Cannot proceed with inference.\")\n",
    "    else:\n",
    "        # Load the trained model\n",
    "        print(f\"Loading trained model from {TRAINED_MODEL_PATH}\")\n",
    "        try:\n",
    "            model_trained = YOLO(TRAINED_MODEL_PATH)\n",
    "            print(\"Trained model loaded successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during trained model loading: {e}\")\n",
    "            model_trained = None # Ensure it's None if loading failed\n",
    "else:\n",
    "    print(\n",
    "        \"Skipping trained model loading because training did not complete successfully \"\n",
    "        \"or results directory is unknown.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4d0bdd",
   "metadata": {},
   "source": [
    "### Inference on an Image\n",
    "\n",
    "Use the loaded trained model to run prediction on a sample image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a10f93",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# --- Inference on a Test Image ---\n",
    "\n",
    "# Get a sample image from the test set (or you can specify your own)\n",
    "if model_trained:\n",
    "    try:\n",
    "        # Try to use a test image from the dataset\n",
    "        test_example = ds['test'][0]\n",
    "        test_img = test_example['image']\n",
    "        test_img_path = 'test_image.jpg'\n",
    "        test_img.save(test_img_path)\n",
    "        \n",
    "        print(f\"\\nRunning inference on: {test_img_path}\")\n",
    "        \n",
    "        # Run inference\n",
    "        predict_results = model_trained.predict(\n",
    "            source=test_img_path,\n",
    "            save=True,\n",
    "            conf=0.5,\n",
    "            device='cuda',\n",
    "        )\n",
    "        \n",
    "        # Results are saved in `runs/detect/predict*` directory\n",
    "        print(\"Prediction results saved.\")\n",
    "\n",
    "        # Display the saved prediction image\n",
    "        predict_save_dir = predict_results[0].save_dir\n",
    "        img_base_name = os.path.basename(test_img_path)\n",
    "        predicted_image_path = os.path.join(predict_save_dir, img_base_name)\n",
    "\n",
    "        if os.path.exists(predicted_image_path):\n",
    "            print(\"\\nDisplaying Prediction Result:\")\n",
    "            display(Image(filename=predicted_image_path))\n",
    "        else:\n",
    "             print(f\"Could not find saved prediction image at {predicted_image_path}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during inference: {e}\")\n",
    "elif TRAINING_SUCCESS:\n",
    "     print(\"Skipping inference because the trained model failed to load.\")\n",
    "else:\n",
    "    print(\"Skipping inference because training did not complete successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238b71b0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Optional: Evaluate Model on Test Set\n",
    "if model_trained:\n",
    "    try:\n",
    "        print(\"\\nEvaluating model on test set...\")\n",
    "        metrics = model_trained.val(data=DATA_YAML_PATH, split='test')\n",
    "        print(f\"Model evaluation complete. mAP50-95: {metrics.box.map}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during evaluation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38a3c67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
