{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e84be410",
   "metadata": {},
   "source": [
    "# YOLOv11 Helmet Detection: Training and Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0ee99c3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting uv\n",
      "  Using cached uv-0.6.14-py3-none-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Using cached uv-0.6.14-py3-none-macosx_11_0_arm64.whl (15.1 MB)\n",
      "Installing collected packages: uv\n",
      "Successfully installed uv-0.6.14\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 254ms\u001b[0m\u001b[0m                                          \u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 0.25ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m55 packages\u001b[0m \u001b[2min 1.08s\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)                                                   \n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)----\u001b[0m\u001b[0m     0 B/113.53 KiB                    \u001b[1A\n",
      "\u001b[2mdill      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/113.53 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)----\u001b[0m\u001b[0m     0 B/119.37 KiB                    \u001b[2A\n",
      "\u001b[2mdill      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 16.00 KiB/113.53 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)----\u001b[0m\u001b[0m     0 B/119.37 KiB                    \u001b[2A\n",
      "\u001b[2mdill      \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 16.00 KiB/113.53 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)----\u001b[0m\u001b[0m 14.92 KiB/119.37 KiB                  \u001b[2A\n",
      "\u001b[2mdill      \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 32.00 KiB/113.53 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)----\u001b[0m\u001b[0m 14.92 KiB/119.37 KiB                  \u001b[2A\n",
      "\u001b[2mdill      \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 48.00 KiB/113.53 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)----\u001b[0m\u001b[0m 14.92 KiB/119.37 KiB                  \u001b[2A\n",
      "\u001b[2mdill      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 64.00 KiB/113.53 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)----\u001b[0m\u001b[0m 14.92 KiB/119.37 KiB                  \u001b[2A\n",
      "\u001b[2mdill      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 64.00 KiB/113.53 KiB\n",
      "\u001b[2mfrozenlist\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 14.92 KiB/119.37 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)----\u001b[0m\u001b[0m     0 B/179.55 KiB                    \u001b[3A\n",
      "\u001b[2mdill      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 64.00 KiB/113.53 KiB\n",
      "\u001b[2mfrozenlist\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 14.92 KiB/119.37 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)----\u001b[0m\u001b[0m 14.88 KiB/179.55 KiB                  \u001b[3A\n",
      "\u001b[2mdill      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 64.00 KiB/113.53 KiB\n",
      "\u001b[2mfrozenlist\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 14.92 KiB/119.37 KiB\n",
      "\u001b[2mfsspec    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.88 KiB/179.55 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)----\u001b[0m\u001b[0m     0 B/479.66 KiB                    \u001b[4A\n",
      "\u001b[2mdill      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 64.00 KiB/113.53 KiB\n",
      "\u001b[2mfrozenlist\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 14.92 KiB/119.37 KiB\n",
      "\u001b[2mfsspec    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.88 KiB/179.55 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)----\u001b[0m\u001b[0m 14.92 KiB/479.66 KiB                  \u001b[4A\n",
      "\u001b[2mdill      \u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 64.00 KiB/113.53 KiB\n",
      "\u001b[2mfrozenlist\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 30.92 KiB/119.37 KiB\n",
      "\u001b[2mfsspec    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.88 KiB/179.55 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)----\u001b[0m\u001b[0m 14.92 KiB/479.66 KiB                  \u001b[4A\n",
      "\u001b[2mdill      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 80.00 KiB/113.53 KiB\n",
      "\u001b[2mfrozenlist\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 30.92 KiB/119.37 KiB\n",
      "\u001b[2mfsspec    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.88 KiB/179.55 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)----\u001b[0m\u001b[0m 14.92 KiB/479.66 KiB                  \u001b[4A\n",
      "\u001b[2mdill      \u001b[0m \u001b[32m----------------------\u001b[2m--------\u001b[0m\u001b[0m 80.00 KiB/113.53 KiB\n",
      "\u001b[2mfrozenlist\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 46.92 KiB/119.37 KiB\n",
      "\u001b[2mfsspec    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.88 KiB/179.55 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)----\u001b[0m\u001b[0m 14.92 KiB/479.66 KiB                  \u001b[4A\n",
      "\u001b[2mdill      \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 96.00 KiB/113.53 KiB\n",
      "\u001b[2mfrozenlist\u001b[0m \u001b[32m------------\u001b[2m------------------\u001b[0m\u001b[0m 46.92 KiB/119.37 KiB\n",
      "\u001b[2mfsspec    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.88 KiB/179.55 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)----\u001b[0m\u001b[0m 14.92 KiB/479.66 KiB                  \u001b[4A\n",
      "\u001b[2mdill      \u001b[0m \u001b[32m--------------------------\u001b[2m----\u001b[0m\u001b[0m 96.00 KiB/113.53 KiB\n",
      "\u001b[2mfrozenlist\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 62.92 KiB/119.37 KiB\n",
      "\u001b[2mfsspec    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.88 KiB/179.55 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)----\u001b[0m\u001b[0m 14.92 KiB/479.66 KiB                  \u001b[4A\n",
      "\u001b[2mdill      \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 112.00 KiB/113.53 KiB\n",
      "\u001b[2mfrozenlist\u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 62.92 KiB/119.37 KiB\n",
      "\u001b[2mfsspec    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.88 KiB/179.55 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)----\u001b[0m\u001b[0m 14.92 KiB/479.66 KiB                  \u001b[4A\n",
      "\u001b[2mdill      \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 112.00 KiB/113.53 KiB\n",
      "\u001b[2mfrozenlist\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 64.07 KiB/119.37 KiB\n",
      "\u001b[2mfsspec    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.88 KiB/179.55 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)----\u001b[0m\u001b[0m 14.92 KiB/479.66 KiB                  \u001b[4A\n",
      "\u001b[2mdill      \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 113.53 KiB/113.53 KiB\n",
      "\u001b[2mfrozenlist\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 64.07 KiB/119.37 KiB\n",
      "\u001b[2mfsspec    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.88 KiB/179.55 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)----\u001b[0m\u001b[0m 14.92 KiB/479.66 KiB                  \u001b[4A\n",
      "\u001b[2mxxhash    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 14.92 KiB/30.08 KiB\n",
      "\u001b[2myarl      \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/92.43 KiB\n",
      "\u001b[2mfrozenlist\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 64.07 KiB/119.37 KiB\n",
      "\u001b[2mmultiprocess\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/140.16 KiB\n",
      "\u001b[2mfsspec    \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 14.88 KiB/179.55 KiB\n",
      "\u001b[2maiohttp   \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.92 KiB/447.11 KiB\n",
      "\u001b[2K\u001b[7A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)----\u001b[0m\u001b[0m 14.92 KiB/479.66 KiB                  \u001b[7A\n",
      "\u001b[2mxxhash    \u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 14.92 KiB/30.08 KiB\n",
      "\u001b[2myarl      \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 32.00 KiB/92.43 KiB\n",
      "\u001b[2mfrozenlist\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 78.92 KiB/119.37 KiB\n",
      "\u001b[2mmultiprocess\u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 14.91 KiB/140.16 KiB\n",
      "\u001b[2mfsspec    \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 30.88 KiB/179.55 KiB\n",
      "\u001b[2maiohttp   \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 14.92 KiB/447.11 KiB\n",
      "\u001b[2K\u001b[7A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)----\u001b[0m\u001b[0m 30.92 KiB/479.66 KiB                  \u001b[7A\n",
      "\u001b[2myarl      \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 48.00 KiB/92.43 KiB\n",
      "\u001b[2mfrozenlist\u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 94.92 KiB/119.37 KiB\n",
      "\u001b[2mmultiprocess\u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 30.91 KiB/140.16 KiB\n",
      "\u001b[2mfsspec    \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 47.86 KiB/179.55 KiB\n",
      "\u001b[2maiohttp   \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 30.92 KiB/447.11 KiB\n",
      "\u001b[2K\u001b[6A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/8)----\u001b[0m\u001b[0m 46.92 KiB/479.66 KiB                  \u001b[6A\n",
      "\u001b[2myarl      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 62.08 KiB/92.43 KiB\n",
      "\u001b[2mmultiprocess\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 51.13 KiB/140.16 KiB\n",
      "\u001b[2mfsspec    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 78.16 KiB/179.55 KiB\n",
      "\u001b[2maiohttp   \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 62.92 KiB/447.11 KiB\n",
      "\u001b[2K\u001b[5A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (3/8)----\u001b[0m\u001b[0m 78.92 KiB/479.66 KiB                  \u001b[5A\n",
      "\u001b[2myarl      \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 62.08 KiB/92.43 KiB\n",
      "\u001b[2mmultiprocess\u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 51.13 KiB/140.16 KiB\n",
      "\u001b[2mfsspec    \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 78.16 KiB/179.55 KiB\n",
      "\u001b[2maiohttp   \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 78.92 KiB/447.11 KiB\n",
      "\u001b[2K\u001b[5A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (3/8)----\u001b[0m\u001b[0m 78.92 KiB/479.66 KiB                  \u001b[5A\n",
      "\u001b[2mmultiprocess\u001b[0m \u001b[32m-----------------\u001b[2m-------------\u001b[0m\u001b[0m 78.91 KiB/140.16 KiB\n",
      "\u001b[2mfsspec    \u001b[0m \u001b[32m-------------------\u001b[2m-----------\u001b[0m\u001b[0m 110.16 KiB/179.55 KiB\n",
      "\u001b[2maiohttp   \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 78.92 KiB/447.11 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (3/8)----\u001b[0m\u001b[0m 126.92 KiB/479.66 KiB                 \u001b[4A\n",
      "\u001b[2mmultiprocess\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 140.16 KiB/140.16 KiB\n",
      "\u001b[2mfsspec    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 142.16 KiB/179.55 KiB\n",
      "\u001b[2maiohttp   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 142.92 KiB/447.11 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (3/8)----\u001b[0m\u001b[0m 190.76 KiB/479.66 KiB                 \u001b[4A\n",
      "\u001b[2mfsspec    \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 142.16 KiB/179.55 KiB\n",
      "\u001b[2maiohttp   \u001b[0m \u001b[32m----------\u001b[2m--------------------\u001b[0m\u001b[0m 142.92 KiB/447.11 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (3/8)----\u001b[0m\u001b[0m 190.76 KiB/479.66 KiB                 \u001b[3A\n",
      "\u001b[2maiohttp   \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 190.92 KiB/447.11 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (3/8)----\u001b[0m\u001b[0m 206.92 KiB/479.66 KiB                 \u001b[2A\n",
      "\u001b[2maiohttp   \u001b[0m \u001b[32m---------------------\u001b[2m---------\u001b[0m\u001b[0m 302.92 KiB/447.11 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (3/8)----\u001b[0m\u001b[0m 366.92 KiB/479.66 KiB                 \u001b[2A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m8 packages\u001b[0m \u001b[2min 332ms\u001b[0m\u001b[0m                                                 \u001b[1A\n",
      "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 4ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m13 packages\u001b[0m \u001b[2min 13ms\u001b[0m\u001b[0m                               \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiohappyeyeballs\u001b[0m\u001b[2m==2.6.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiohttp\u001b[0m\u001b[2m==3.11.18\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiosignal\u001b[0m\u001b[2m==1.3.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdatasets\u001b[0m\u001b[2m==3.5.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdill\u001b[0m\u001b[2m==0.3.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfrozenlist\u001b[0m\u001b[2m==1.6.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.3.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2024.12.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.30.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmultidict\u001b[0m\u001b[2m==6.4.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmultiprocess\u001b[0m\u001b[2m==0.70.16\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpropcache\u001b[0m\u001b[2m==0.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mxxhash\u001b[0m\u001b[2m==3.5.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1myarl\u001b[0m\u001b[2m==1.20.0\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m2 packages\u001b[0m \u001b[2min 8ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install uv && uv pip install --upgrade pip && uv pip install -r requirements.txt\n",
    "!uv pip install datasets ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8babf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sam/HKBU_HDDS_YR2_HW/HDDS2302_Applied Deep Learning_Final/project-py/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Imports Loaded ---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "from datasets import load_dataset\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"--- Imports Loaded ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ff108d",
   "metadata": {},
   "source": [
    "## Section 1: Load Dataset from Hugging Face\n",
    "\n",
    "Load the helmet detection dataset from Hugging Face instead of using a local dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf30836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Section 1: Load Dataset from Hugging Face ---\n",
    "ds = load_dataset(\"keremberke/hard-hat-detection\", name=\"full\")\n",
    "print(f\"Dataset loaded with {len(ds['train'])} training, {len(ds['validation'])} validation, and {len(ds['test'])} test examples\")\n",
    "\n",
    "# Display an example\n",
    "example = ds['train'][0]\n",
    "print(\"Sample example keys:\", example.keys())\n",
    "print(f\"Image dimensions: {example['image'].size}\")\n",
    "print(f\"Annotations: {example['objects']}\")\n",
    "\n",
    "# Display the first image with its annotations\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(example['image'])\n",
    "for obj in example['objects']:\n",
    "    bbox = obj['bbox']\n",
    "    xmin, ymin, xmax, ymax = bbox['xmin'], bbox['ymin'], bbox['xmax'], bbox['ymax']\n",
    "    category = obj['category']\n",
    "    plt.gca().add_patch(plt.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, \n",
    "                                    fill=False, edgecolor='red', linewidth=2))\n",
    "    plt.text(xmin, ymin, category, bbox=dict(facecolor='red', alpha=0.5))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ce00f6",
   "metadata": {},
   "source": [
    "## Section 2: Convert Dataset to YOLO Format\n",
    "\n",
    "The Hugging Face dataset needs to be converted to a format compatible with YOLO training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9924b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Section 2: Convert Dataset to YOLO Format ---\n",
    "# Create directories for YOLO dataset\n",
    "DATASET_DIR = Path('hf_helmet_dataset')\n",
    "IMAGES_DIR = DATASET_DIR / 'images'\n",
    "LABELS_DIR = DATASET_DIR / 'labels'\n",
    "\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    (IMAGES_DIR / split).mkdir(parents=True, exist_ok=True)\n",
    "    (LABELS_DIR / split).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define class mapping\n",
    "class_map = {\n",
    "    'helmet': 0,\n",
    "    'head': 1,\n",
    "    'person': 2\n",
    "}\n",
    "\n",
    "# Function to convert dataset to YOLO format\n",
    "def convert_to_yolo_format(dataset, split):\n",
    "    for i, example in enumerate(dataset[split]):\n",
    "        # Save image\n",
    "        img = example['image']\n",
    "        img_path = IMAGES_DIR / split / f\"{i}.jpg\"\n",
    "        img.save(img_path)\n",
    "        \n",
    "        # Create YOLO format labels\n",
    "        img_width, img_height = img.size\n",
    "        label_path = LABELS_DIR / split / f\"{i}.txt\"\n",
    "        \n",
    "        with open(label_path, 'w') as f:\n",
    "            for obj in example['objects']:\n",
    "                # Convert bbox to YOLO format: class_id, x_center, y_center, width, height (normalized)\n",
    "                bbox = obj['bbox']\n",
    "                xmin, ymin, xmax, ymax = bbox['xmin'], bbox['ymin'], bbox['xmax'], bbox['ymax']\n",
    "                \n",
    "                # Convert to YOLO format (normalized)\n",
    "                x_center = ((xmin + xmax) / 2) / img_width\n",
    "                y_center = ((ymin + ymax) / 2) / img_height\n",
    "                width = (xmax - xmin) / img_width\n",
    "                height = (ymax - ymin) / img_height\n",
    "                \n",
    "                # Get class id\n",
    "                class_name = obj['category']\n",
    "                class_id = class_map.get(class_name, 0)  # Default to 0 if not found\n",
    "                \n",
    "                # Write to file\n",
    "                f.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
    "    \n",
    "    return len(dataset[split])\n",
    "\n",
    "# Convert the datasets\n",
    "print(\"Converting dataset to YOLO format...\")\n",
    "train_count = convert_to_yolo_format(ds, 'train')\n",
    "val_count = convert_to_yolo_format(ds, 'validation')\n",
    "test_count = convert_to_yolo_format(ds, 'test')\n",
    "print(f\"Converted {train_count} training, {val_count} validation, and {test_count} test examples\")\n",
    "\n",
    "# Create YAML configuration for YOLO\n",
    "yaml_content = {\n",
    "    'path': str(DATASET_DIR.absolute()),\n",
    "    'train': str(IMAGES_DIR / 'train'),\n",
    "    'val': str(IMAGES_DIR / 'validation'),\n",
    "    'test': str(IMAGES_DIR / 'test'),\n",
    "    'nc': len(class_map),\n",
    "    'names': list(class_map.keys())\n",
    "}\n",
    "\n",
    "# Save YAML file\n",
    "yaml_path = DATASET_DIR / 'data.yaml'\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(yaml_content, f)\n",
    "\n",
    "print(f\"Created YOLO configuration at {yaml_path}\")\n",
    "print(yaml_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be96a17",
   "metadata": {},
   "source": [
    "## Section 3: Define Configuration and Model\n",
    "\n",
    "Define paths, model variant, and load the base model and dataset configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034cdff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Section 3: Define Configuration and Model ---\n",
    "DATA_YAML_PATH = str(yaml_path)  # Use the newly created YAML file\n",
    "MODEL_VARIANT = 'yolo11n.pt'  # Using YOLOv11 nano variant\n",
    "\n",
    "# Load the base model\n",
    "model = YOLO(MODEL_VARIANT)\n",
    "print(f\"Base model '{MODEL_VARIANT}' loaded.\")\n",
    "\n",
    "# Verify dataset configuration\n",
    "try:\n",
    "    with open(DATA_YAML_PATH, 'r') as f:\n",
    "        data_config = yaml.safe_load(f)\n",
    "        print(\"Dataset configuration loaded successfully:\")\n",
    "        print(data_config)\n",
    "        # Basic validation (check if paths exist)\n",
    "        required_paths = [\n",
    "            data_config.get('train'),\n",
    "            data_config.get('val'),\n",
    "            data_config.get('test')\n",
    "        ]\n",
    "        for p in required_paths:\n",
    "            if p and not os.path.exists(p):\n",
    "                print(\n",
    "                    f\"Warning: Path '{p}' specified in {DATA_YAML_PATH} \"\n",
    "                    f\"might not exist relative to the current directory.\"\n",
    "                )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading or validating {DATA_YAML_PATH}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb99d156",
   "metadata": {},
   "source": [
    "## Section 4: Train the Model\n",
    "\n",
    "Define training parameters and start the training process using the loaded configuration and base model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e6ca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Section 4: Train the Model ---\n",
    "# Training parameters\n",
    "EPOCHS = 50\n",
    "IMG_SIZE = 640\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "print(f\"Starting training for {EPOCHS} epochs...\")\n",
    "\n",
    "# Initialize variables for results\n",
    "results_dir = None\n",
    "TRAINING_SUCCESS = False\n",
    "\n",
    "# Start training\n",
    "try:\n",
    "    results = model.train(\n",
    "        data=DATA_YAML_PATH,\n",
    "        epochs=EPOCHS,\n",
    "        imgsz=IMG_SIZE,\n",
    "        batch=BATCH_SIZE,\n",
    "        # device='mps',          # Specify Apple Silicon GPU\n",
    "        device='cuda',          # Specify Nvidia GPU\n",
    "        cache=True,             # Cache dataset images in RAM\n",
    "        amp=True,              # Ensure Automatic Mixed Precision is enabled\n",
    "        workers=8,             # Number of worker threads\n",
    "        project='runs/detect',  # Project directory for results\n",
    "        name='helmet_train'     # Experiment name\n",
    "    )\n",
    "\n",
    "    print(\"Training finished.\")\n",
    "    # Store the results directory for later use\n",
    "    results_dir = results.save_dir\n",
    "    print(f\"Results saved to: {results_dir}\")\n",
    "    TRAINING_SUCCESS = True\n",
    "\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"An error occurred during training: {e}\", traceback.format_exc())\n",
    "    TRAINING_SUCCESS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf9efb6",
   "metadata": {},
   "source": [
    "## Display Training Results\n",
    "\n",
    "If training completed successfully, display the generated plots and validation images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921132f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display paths to important results files (plots)\n",
    "if TRAINING_SUCCESS and results_dir:\n",
    "    print(\"Displaying training results plots:\")\n",
    "\n",
    "    confusion_matrix_path = os.path.join(results_dir, 'confusion_matrix.png')\n",
    "    results_plot_path = os.path.join(results_dir, 'results.png')\n",
    "    val_labels_path = os.path.join(results_dir, 'val_batch0_labels.jpg')\n",
    "    val_pred_path = os.path.join(results_dir, 'val_batch0_pred.jpg')\n",
    "\n",
    "    if os.path.exists(confusion_matrix_path):\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        display(Image(filename=confusion_matrix_path))\n",
    "    else:\n",
    "        print(f\"Confusion matrix not found at: {confusion_matrix_path}\")\n",
    "\n",
    "    if os.path.exists(results_plot_path):\n",
    "        print(\"\\nResults Plot:\")\n",
    "        display(Image(filename=results_plot_path))\n",
    "    else:\n",
    "        print(f\"Results plot not found at: {results_plot_path}\")\n",
    "\n",
    "    if os.path.exists(val_labels_path):\n",
    "        print(\"\\nValidation Batch 0 Labels:\")\n",
    "        display(Image(filename=val_labels_path))\n",
    "    else:\n",
    "        print(f\"Validation labels image not found at: {val_labels_path}\")\n",
    "\n",
    "    if os.path.exists(val_pred_path):\n",
    "        print(\"\\nValidation Batch 0 Predictions:\")\n",
    "        display(Image(filename=val_pred_path))\n",
    "    else:\n",
    "        print(f\"Validation predictions image not found at: {val_pred_path}\")\n",
    "elif not TRAINING_SUCCESS:\n",
    "    print(\"Training did not complete successfully. Cannot display results plots.\")\n",
    "else:\n",
    "    print(\"Results directory not found. Cannot display results plots.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2128fcf3",
   "metadata": {},
   "source": [
    "## Section 7: Load Trained Model and Run Inference\n",
    "\n",
    "Load the best weights from the completed training run and prepare for inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfaf26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Section 7: Load Trained Model ---\n",
    "\n",
    "model_trained = None # Initialize variable\n",
    "\n",
    "# Only proceed if training seemed to complete and results were saved\n",
    "if TRAINING_SUCCESS and results_dir:\n",
    "    # Path to the trained model weights\n",
    "    TRAINED_MODEL_PATH = os.path.join(results_dir, 'weights/best.pt')\n",
    "\n",
    "    # Check if the trained model file exists\n",
    "    if not os.path.exists(TRAINED_MODEL_PATH):\n",
    "        print(f\"Error: Trained model not found at {TRAINED_MODEL_PATH}\")\n",
    "        print(\"Cannot proceed with inference.\")\n",
    "    else:\n",
    "        # Load the trained model\n",
    "        print(f\"Loading trained model from {TRAINED_MODEL_PATH}\")\n",
    "        try:\n",
    "            model_trained = YOLO(TRAINED_MODEL_PATH)\n",
    "            print(\"Trained model loaded successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during trained model loading: {e}\")\n",
    "            model_trained = None # Ensure it's None if loading failed\n",
    "else:\n",
    "    print(\n",
    "        \"Skipping trained model loading because training did not complete successfully \"\n",
    "        \"or results directory is unknown.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c795b0",
   "metadata": {},
   "source": [
    "### Inference on an Image\n",
    "\n",
    "Use the loaded trained model to run prediction on a sample image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b02025",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# --- Inference on a Test Image ---\n",
    "\n",
    "# Get a sample image from the test set (or you can specify your own)\n",
    "if model_trained:\n",
    "    try:\n",
    "        # Try to use a test image from the dataset\n",
    "        test_example = ds['test'][0]\n",
    "        test_img = test_example['image']\n",
    "        test_img_path = 'test_image.jpg'\n",
    "        test_img.save(test_img_path)\n",
    "        \n",
    "        print(f\"\\nRunning inference on: {test_img_path}\")\n",
    "        \n",
    "        # Run inference\n",
    "        predict_results = model_trained.predict(\n",
    "            source=test_img_path,\n",
    "            save=True,\n",
    "            conf=0.5,\n",
    "            device='cuda',\n",
    "        )\n",
    "        \n",
    "        # Results are saved in `runs/detect/predict*` directory\n",
    "        print(\"Prediction results saved.\")\n",
    "\n",
    "        # Display the saved prediction image\n",
    "        predict_save_dir = predict_results[0].save_dir\n",
    "        img_base_name = os.path.basename(test_img_path)\n",
    "        predicted_image_path = os.path.join(predict_save_dir, img_base_name)\n",
    "\n",
    "        if os.path.exists(predicted_image_path):\n",
    "            print(\"\\nDisplaying Prediction Result:\")\n",
    "            display(Image(filename=predicted_image_path))\n",
    "        else:\n",
    "             print(f\"Could not find saved prediction image at {predicted_image_path}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during inference: {e}\")\n",
    "elif TRAINING_SUCCESS:\n",
    "     print(\"Skipping inference because the trained model failed to load.\")\n",
    "else:\n",
    "    print(\"Skipping inference because training did not complete successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11448cf",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Optional: Evaluate Model on Test Set\n",
    "if model_trained:\n",
    "    try:\n",
    "        print(\"\\nEvaluating model on test set...\")\n",
    "        metrics = model_trained.val(data=DATA_YAML_PATH, split='test')\n",
    "        print(f\"Model evaluation complete. mAP50-95: {metrics.box.map}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during evaluation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be423f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
